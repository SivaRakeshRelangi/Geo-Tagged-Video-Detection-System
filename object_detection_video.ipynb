{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "0) Setup (Colab) â€” installs and environment check"
      ],
      "metadata": {
        "id": "pmlvd2ClVGdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L-XS1h3fU3nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975bb994-6270-422d-8677-7ecbb00bd748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.6/1.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTorch: 2.8.0+cu126 | CUDA available: False\n",
            "Python: 3.12.11\n"
          ]
        }
      ],
      "source": [
        "# Install system OCR tool (Tesseract)\n",
        "!apt-get -y install tesseract-ocr >/dev/null\n",
        "\n",
        "# Install all required Python packages\n",
        "!pip -q install opencv-python pillow pytesseract torch torchvision matplotlib pandas tqdm ultralytics\n",
        "\n",
        "import torch, platform\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Python:\", platform.python_version())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= IMPORTS =======\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from datetime import timedelta\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "\n",
        "# ======= USER INPUTS =======\n",
        "VIDEO_PATH   = Path(\"demovidlos.mp4\")  # Set your video file here\n",
        "DESIRED_FPS  = 2.0                     # Desired frames per second\n",
        "\n",
        "# Uncomment and set tesseract path if on Windows\n",
        "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\sivar\\AppData\\Local\\Programs\\Tesseract-OCR\"\n",
        "\n",
        "# ======= OUTPUT FOLDERS =======\n",
        "OUT_ROOT   = Path(\"/content/dataset_pipeline\")\n",
        "FRAMES_DIR = OUT_ROOT / \"images\"\n",
        "LABELS_DIR = OUT_ROOT / \"labels\"  # Reserved for future use if needed\n",
        "META_CSV   = OUT_ROOT / \"metadata.csv\"\n",
        "\n",
        "for d in [OUT_ROOT, FRAMES_DIR, LABELS_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Video:\", VIDEO_PATH)\n",
        "print(\"Output root:\", OUT_ROOT)\n",
        "\n",
        "# ======= FRAME EXTRACTION + OCR (ORIGINAL SHAPE) =======\n",
        "def extract_frames_with_ocr(video_path, out_dir):\n",
        "    \"\"\"\n",
        "    Extract frames every (1 / DESIRED_FPS) seconds at original resolution.\n",
        "    Apply OCR and save metadata (image, timestamp, OCR text).\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 0.0\n",
        "    print(\"Original FPS\",fps)\n",
        "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
        "    duration = (frames / fps) if (fps > 0 and frames > 0) else None\n",
        "\n",
        "    interval = 1.0 / DESIRED_FPS\n",
        "    t = 0.0\n",
        "    rows, saved = [], 0\n",
        "\n",
        "    while True:\n",
        "        if duration is not None and t > duration:\n",
        "            break\n",
        "\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, t * 1000.0)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        fname = f\"sec_{int(round(t * 1000)):010d}.jpg\"\n",
        "        fpath = out_dir / fname\n",
        "        cv2.imwrite(str(fpath), frame)\n",
        "        saved += 1\n",
        "\n",
        "        # Apply OCR to the full frame\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        ocr_text = pytesseract.image_to_string(gray).strip()\n",
        "\n",
        "        rows.append({\n",
        "            \"image\": fname,\n",
        "            \"time_seconds\": round(t, 3),\n",
        "            \"timecode\": str(timedelta(seconds=float(t))),\n",
        "            \"ocr_text\": ocr_text,\n",
        "        })\n",
        "\n",
        "        t += interval\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if rows:\n",
        "        pd.DataFrame(rows).to_csv(META_CSV, index=False)\n",
        "\n",
        "    print(f\"âœ… Saved {saved} frames â†’ {out_dir}\")\n",
        "    print(f\"ðŸ“„ Wrote metadata with OCR â†’ {META_CSV}\")\n",
        "\n",
        "# ======= RUN EXTRACTION =======\n",
        "extract_frames_with_ocr(VIDEO_PATH, FRAMES_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_QFBYN_q2Vb",
        "outputId": "f67f6703-7409-4a3b-d7ab-f0d53d2cc8c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: demovidlos.mp4\n",
            "Output root: /content/dataset_pipeline\n",
            "Original FPS 23.976023976023978\n",
            "âœ… Saved 28 frames â†’ /content/dataset_pipeline/images\n",
            "ðŸ“„ Wrote metadata with OCR â†’ /content/dataset_pipeline/metadata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "017h8ZKQVAnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yRXOZ7x9VAYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2, time, os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "cR_urw8oVAM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b2e0e2-7fa4-410c-b6f9-d7d5884777b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input/output paths\n",
        "INPUT_VIDEO  = VIDEO_PATH     # <- change this\n",
        "OUTPUT_VIDEO = \"output_annotated.mp4\"\n",
        "\n",
        "# Pick a model (smallest = yolov8n.pt). Others: yolov8s.pt / m / l / x\n",
        "MODEL_NAME = \"yolov8n.pt\"      # downloads automatically on first run\n",
        "\n",
        "model = YOLO(MODEL_NAME)\n"
      ],
      "metadata": {
        "id": "nOjU2FEhs_pe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"Could not open {INPUT_VIDEO}\")\n",
        "\n",
        "# Get video properties\n",
        "fps     = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "width   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "length  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out    = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))\n",
        "\n",
        "# Process\n",
        "pbar = tqdm(total=length if length > 0 else None, desc=\"Processing\")\n",
        "frame_idx = 0\n",
        "t0 = time.time()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Inference (you can set conf, iou, device=\"0\" for GPU, etc.)\n",
        "    results = model.predict(source=frame, conf=0.25, iou=0.45, verbose=False)\n",
        "    # results is a list; get first result and draw\n",
        "    annotated = results[0].plot()  # draws boxes, labels, confidences\n",
        "\n",
        "    out.write(annotated)\n",
        "\n",
        "    frame_idx += 1\n",
        "    pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pbar.close()\n",
        "\n",
        "elapsed = time.time() - t0\n",
        "print(f\"Saved: {OUTPUT_VIDEO} | Frames: {frame_idx} | Avg FPS: {frame_idx/max(elapsed,1e-6):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhv_uoUDs_Yi",
        "outputId": "a6943c34-d06c-49c3-bece-3d7271991ac4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 332/332 [01:11<00:00,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: output_annotated.mp4 | Frames: 332 | Avg FPS: 4.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xpZsZUEKs_Id"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}